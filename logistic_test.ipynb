{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit ('base': conda)",
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.loadtxt(\"Iris_data\\iris.data\", delimiter=\",\", usecols=[0,1,2,3])[:100]\n",
    "raw_label = np.genfromtxt(\"Iris_data\\iris.data\", delimiter=\",\", usecols=[4], dtype=str)[:100]\n",
    "unique, raw_label = np.unique(raw_label, return_inverse=True)"
   ]
  },
  {
   "source": [
    "## Torch implementation of logistics gradient and hessian"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(np.c_[raw_data, np.ones(raw_data.shape[0])][:80], dtype=torch.double)\n",
    "label = torch.tensor(label[:80])\n",
    "w = torch.zeros(data.shape[1], dtype=torch.double, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.sum(-label*(data@w) + torch.log(1 + torch.exp(data@w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(55.4518, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = torch.autograd.grad(l, w, retain_graph=True, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([ 34.1000,  43.6000, -28.4000, -14.2000,  10.0000], dtype=torch.float64,\n",
       "        grad_fn=<AddBackward0>),)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([593.2700, 342.8650, 290.4825,  77.4225, 108.1000, 342.8650, 206.9750,\n",
      "        153.9850,  39.2050,  63.6500, 290.4825, 153.9850, 169.5250,  49.0475,\n",
      "         50.8000,  77.4225,  39.2050,  49.0475,  14.9450,  13.2000, 108.1000,\n",
      "         63.6500,  50.8000,  13.2000,  20.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "out = torch.tensor([], dtype=torch.double)\n",
    "for i in grad[0]:\n",
    "    out = torch.cat((out, torch.autograd.grad(i, w, retain_graph=True)[0]))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.reshape(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.0666,  0.5309, -0.9120, -0.8924,  1.3559], dtype=torch.float64,\n",
       "       grad_fn=<MvBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "torch.inverse(out)@grad[0]"
   ]
  },
  {
   "source": [
    "## Sample implementation of logistics regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self,max_iter=100,use_matrix=True):\n",
    "        self.beta=None\n",
    "        self.n_features=None\n",
    "        self.max_iter=max_iter\n",
    "        self.use_Hessian=use_matrix\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        n_samples=X.shape[0]\n",
    "        self.n_features=X.shape[1]\n",
    "        extra=np.ones((n_samples,))\n",
    "        X=np.c_[X,extra]\n",
    "        self.beta=np.zeros((X.shape[1],))\n",
    "        for i in range(self.max_iter):\n",
    "            if self.use_Hessian is not True:                \n",
    "                dldbeta=self._dldbeta(X,y,self.beta)                \n",
    "                dldldbetadbeta=self._dldldbetadbeta(X,self.beta)\n",
    "                self.beta-=(1./dldldbetadbeta*dldbeta)\n",
    "            else:\n",
    "                print(i,\" Iter:\")\n",
    "                dldbeta = self._dldbeta(X, y, self.beta)\n",
    "                print(\"Gradient:\", dldbeta)\n",
    "                dldldbetadbeta = self._dldldbetadbeta_matrix(X, self.beta)\n",
    "                # print(\"Hessian:\\n\", dldldbetadbeta)\n",
    "                self.beta -= (np.linalg.inv(dldldbetadbeta).dot(dldbeta))\n",
    "                print(\"#########################################################\")\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _dldbeta(X,y,beta):\n",
    "        # 《机器学习》 公式 3.30\n",
    "        m=X.shape[0]\n",
    "        sum=np.zeros(X.shape[1],).T\n",
    "        for i in range(m):\n",
    "            temp=X[i]*(y[i]-np.exp(X[i].dot(beta))/(1+np.exp(X[i].dot(beta))))\n",
    "            sum+=temp\n",
    "        return -sum\n",
    "\n",
    "    @staticmethod\n",
    "    def _dldldbetadbeta_matrix(X,beta):\n",
    "        m=X.shape[0]\n",
    "        Hessian=np.zeros((X.shape[1],X.shape[1]))\n",
    "        for i in range(m):\n",
    "            p1 = np.exp(X[i].dot(beta)) / (1 + np.exp(X[i].dot(beta)))\n",
    "            tmp=X[i].reshape((-1,1))\n",
    "            Hessian+=tmp.dot(tmp.T)*p1*(1-p1)\n",
    "        return Hessian\n",
    "\n",
    "    @staticmethod\n",
    "    def _dldldbetadbeta(X,beta):\n",
    "        # 《机器学习》公式 3.31\n",
    "        m=X.shape[0]\n",
    "        sum=0.\n",
    "        for i in range(m):\n",
    "            p1=np.exp(X[i].dot(beta))/(1+np.exp(X[i].dot(beta)))\n",
    "            sum+=X[i].dot(X[i].T)*p1*(1-p1)\n",
    "        return sum\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        n_samples = X.shape[0]\n",
    "        extra = np.ones((n_samples,))\n",
    "        X = np.c_[X, extra]\n",
    "        if self.beta is None:\n",
    "            raise RuntimeError('cant predict before fit')\n",
    "        p1 = np.exp(X.dot(self.beta)) / (1 + np.exp(X.dot(self.beta)))\n",
    "        p0 = 1 - p1\n",
    "        return np.c_[p0,p1]\n",
    "\n",
    "    def predict(self,X):\n",
    "        p=self.predict_proba(X)\n",
    "        res=np.argmax(p,axis=1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 34.1  43.6 -28.4 -14.2  10. ]\n",
      "#########################################################\n",
      "1  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 7.29474076 10.16493666 -7.61727457 -3.67118444  2.25290718]\n",
      "#########################################################\n",
      "2  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 2.39325624  3.51588204 -2.83873108 -1.34368637  0.76410355]\n",
      "#########################################################\n",
      "3  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 0.82142273  1.26253837 -1.0812764  -0.50493471  0.27027994]\n",
      "#########################################################\n",
      "4  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 0.28440728  0.45801751 -0.41467947 -0.19129009  0.09667873]\n",
      "#########################################################\n",
      "5  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 0.09817673  0.16656197 -0.15938913 -0.07266519  0.03464679]\n",
      "#########################################################\n",
      "6  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 0.0337334   0.06061194 -0.06120021 -0.02759457  0.01241696]\n",
      "#########################################################\n",
      "7  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 0.01159072  0.02208683 -0.02340321 -0.01045088  0.00445802]\n",
      "#########################################################\n",
      "8  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 0.00401652  0.00807223 -0.00889087 -0.00394029  0.00160858]\n",
      "#########################################################\n",
      "9  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 0.00141598  0.00296299 -0.00335089 -0.0014775   0.00058499]\n",
      "#########################################################\n",
      "10  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 0.00051009  0.00109265 -0.00125303 -0.00055102  0.00021462]\n",
      "#########################################################\n",
      "11  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.87444413e-04  4.04480413e-04 -4.65491719e-04 -2.04566861e-04\n",
      "  7.93370633e-05]\n",
      "#########################################################\n",
      "12  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 6.98690995e-05  1.50100562e-04 -1.72101665e-04 -7.56907080e-05\n",
      "  2.94807491e-05]\n",
      "#########################################################\n",
      "13  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 2.62551580e-05  5.57652942e-05 -6.34306984e-05 -2.79427453e-05\n",
      "  1.09854007e-05]\n",
      "#########################################################\n",
      "14  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 9.89897463e-06  2.07213548e-05 -2.33346011e-05 -1.03009163e-05\n",
      "  4.09745767e-06]\n",
      "#########################################################\n",
      "15  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 3.73325297e-06  7.69624652e-06 -8.57546371e-06 -3.79408972e-06\n",
      "  1.52799090e-06]\n",
      "#########################################################\n",
      "16  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.40595566e-06  2.85629847e-06 -3.14996008e-06 -1.39675403e-06\n",
      "  5.69303779e-07]\n",
      "#########################################################\n",
      "17  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 5.28319945e-07  1.05908662e-06 -1.15686507e-06 -5.14053044e-07\n",
      "  2.11858206e-07]\n",
      "#########################################################\n",
      "18  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.98038525e-07  3.92331043e-07 -4.24883283e-07 -1.89159336e-07\n",
      "  7.87371789e-08]\n",
      "#########################################################\n",
      "19  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 7.40532247e-08  1.45206443e-07 -1.56065445e-07 -6.96003641e-08\n",
      "  2.92252357e-08]\n",
      "#########################################################\n",
      "20  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 2.76286092e-08  5.36987941e-08 -5.73339406e-08 -2.56080524e-08\n",
      "  1.08347624e-08]\n",
      "#########################################################\n",
      "21  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.02873037e-08  1.98439450e-08 -2.10663374e-08 -9.42175307e-09\n",
      "  4.01251742e-09]\n",
      "#########################################################\n",
      "22  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 3.82370812e-09  7.32852400e-09 -7.74168488e-09 -3.46641891e-09\n",
      "  1.48459293e-09]\n",
      "#########################################################\n",
      "23  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.41911472e-09  2.70500615e-09 -2.84540728e-09 -1.27533972e-09\n",
      "  5.48840471e-10]\n",
      "#########################################################\n",
      "24  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 5.26016616e-10  9.97971439e-10 -1.04594200e-09 -4.69208821e-10\n",
      "  2.02761007e-10]\n",
      "#########################################################\n",
      "25  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.94767027e-10  3.68040971e-10 -3.84518797e-10 -1.72624347e-10\n",
      "  7.48628943e-11]\n",
      "#########################################################\n",
      "26  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 7.20515104e-11  1.35684311e-10 -1.41372807e-10 -6.35085868e-11\n",
      "  2.76270035e-11]\n",
      "#########################################################\n",
      "27  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 2.66344513e-11  5.00081052e-11 -5.19812307e-11 -2.33645588e-11\n",
      "  1.01910337e-11]\n",
      "#########################################################\n",
      "28  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 9.84009596e-12  1.84270380e-11 -1.91136368e-11 -8.59548062e-12\n",
      "  3.75804020e-12]\n",
      "#########################################################\n",
      "29  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 3.63339506e-12  6.78860646e-12 -7.02857849e-12 -3.16214349e-12\n",
      "  1.38538671e-12]\n",
      "#########################################################\n",
      "30  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.34103703e-12  2.50053461e-12 -2.58467233e-12 -1.16326795e-12\n",
      "  5.10588864e-13]\n",
      "#########################################################\n",
      "31  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 4.94577874e-13  9.20801190e-13 -9.50633757e-13 -4.27986836e-13\n",
      "  1.88108519e-13]\n",
      "#########################################################\n",
      "32  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.82698843e-13  3.39216972e-13 -3.49415834e-13 -1.57387028e-13\n",
      "  6.93592675e-14]\n",
      "#########################################################\n",
      "33  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 6.74623661e-14  1.24945672e-13 -1.28444921e-13 -5.78801939e-14\n",
      "  2.55659919e-14]\n",
      "#########################################################\n",
      "34  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 2.46957426e-14  4.59222432e-14 -4.73404717e-14 -2.13227296e-14\n",
      "  9.38888507e-15]\n",
      "#########################################################\n",
      "35  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 9.36713810e-15  1.70483258e-14 -1.72418524e-14 -7.77737273e-15\n",
      "  3.50299729e-15]\n",
      "#########################################################\n",
      "36  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 3.50893257e-15  6.29755650e-15 -6.31392374e-15 -2.85457356e-15\n",
      "  1.29619150e-15]\n",
      "#########################################################\n",
      "37  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 1.18218276e-15  2.26745599e-15 -2.39048840e-15 -1.06962572e-15\n",
      "  4.57663656e-16]\n",
      "#########################################################\n",
      "38  Iter:\n",
      "\n",
      "Gradient:\n",
      " [ 4.02216936e-16  8.11618386e-16 -9.13438995e-16 -4.05934687e-16\n",
      "  1.56024041e-16]\n",
      "#########################################################\n",
      "39  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-2.73518226e-16  8.99600619e-17 -6.23899189e-16 -2.37276526e-16\n",
      " -3.05107166e-17]\n",
      "#########################################################\n",
      "40  Iter:\n",
      "\n",
      "Gradient:\n",
      " [5.32627956e-16 3.35432570e-16 1.83081671e-16 3.52619724e-17\n",
      " 1.11337569e-16]\n",
      "#########################################################\n",
      "41  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.52490281e-15 -6.98166292e-16 -1.05397327e-15 -3.20094753e-16\n",
      " -2.92108105e-16]\n",
      "#########################################################\n",
      "42  Iter:\n",
      "\n",
      "Gradient:\n",
      " [7.21062023e-17 4.54082554e-17 2.47882794e-17 4.77495535e-18\n",
      " 1.50719586e-17]\n",
      "#########################################################\n",
      "43  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.69431930e-15 -8.04860275e-16 -1.11220616e-15 -3.31310299e-16\n",
      " -3.27522244e-16]\n",
      "#########################################################\n",
      "44  Iter:\n",
      "\n",
      "Gradient:\n",
      " [9.76132101e-18 6.14685728e-18 3.35605942e-18 6.46557877e-19\n",
      " 2.04026162e-18]\n",
      "#########################################################\n",
      "45  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-6.29236135e-16 -2.86396684e-16 -3.87343433e-16 -1.10784447e-16\n",
      " -1.10271732e-16]\n",
      "#########################################################\n",
      "46  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.32136015e-18 8.32057955e-19 4.54344218e-19 8.75405522e-20\n",
      " 2.76177292e-19]\n",
      "#########################################################\n",
      "47  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.72035959e-15 -8.21258941e-16 -1.12115811e-15 -3.33034703e-16\n",
      " -3.32965307e-16]\n",
      "#########################################################\n",
      "48  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.78869482e-19 1.12629749e-19 6.15088932e-20 1.18523968e-20\n",
      " 3.73838809e-20]\n",
      "#########################################################\n",
      "49  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-6.32761322e-16 -2.88616552e-16 -3.88555431e-16 -1.11017942e-16\n",
      " -1.11008550e-16]\n",
      "#########################################################\n",
      "50  Iter:\n",
      "\n",
      "Gradient:\n",
      " [2.42118331e-20 1.52452625e-20 8.32651461e-21 1.60460312e-21\n",
      " 5.06019726e-21]\n",
      "#########################################################\n",
      "51  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.72083678e-15 -8.21559430e-16 -1.12132219e-15 -3.33066317e-16\n",
      " -3.33065046e-16]\n",
      "#########################################################\n",
      "52  Iter:\n",
      "\n",
      "Gradient:\n",
      " [3.27737425e-21 2.06357176e-21 1.12717709e-21 2.17236143e-22\n",
      " 6.84933487e-22]\n",
      "#########################################################\n",
      "53  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.72084448e-15 -8.21564279e-16 -1.12132484e-15 -3.33066827e-16\n",
      " -3.33066655e-16]\n",
      "#########################################################\n",
      "54  Iter:\n",
      "\n",
      "Gradient:\n",
      " [4.43625826e-22 2.79317211e-22 1.52584530e-22 2.94091535e-23\n",
      " 9.27091924e-23]\n",
      "#########################################################\n",
      "55  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-6.32826961e-16 -2.88657884e-16 -3.88578002e-16 -1.11022292e-16\n",
      " -1.11022268e-16]\n",
      "#########################################################\n",
      "56  Iter:\n",
      "\n",
      "Gradient:\n",
      " [6.00466508e-23 3.78061877e-23 2.06541109e-23 3.98110281e-24\n",
      " 1.25484132e-23]\n",
      "#########################################################\n",
      "57  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-6.32827102e-16 -2.88657972e-16 -3.88578051e-16 -1.11022301e-16\n",
      " -1.11022298e-16]\n",
      "#########################################################\n",
      "58  Iter:\n",
      "\n",
      "Gradient:\n",
      " [8.12709236e-24 5.11685646e-24 2.79559252e-24 5.38881406e-25\n",
      " 1.69836073e-24]\n",
      "#########################################################\n",
      "59  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.17683640e-15 -5.55111510e-16 -7.54951656e-16 -2.22044605e-16\n",
      " -2.22044604e-16]\n",
      "#########################################################\n",
      "60  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.10004283e-24 6.92574951e-25 3.78415273e-25 7.29477246e-26\n",
      " 2.29873690e-25]\n",
      "#########################################################\n",
      "61  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-6.32827124e-16 -2.88657986e-16 -3.88578058e-16 -1.11022302e-16\n",
      " -1.11022302e-16]\n",
      "#########################################################\n",
      "62  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.50588097e-25 9.47939686e-26 5.17968703e-26 9.98879916e-27\n",
      " 3.14686077e-26]\n",
      "#########################################################\n",
      "63  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.17683641e-15 -5.55111512e-16 -7.54951657e-16 -2.22044605e-16\n",
      " -2.22044605e-16]\n",
      "#########################################################\n",
      "64  Iter:\n",
      "\n",
      "Gradient:\n",
      " [2.03786255e-26 1.28279378e-26 7.00980297e-27 1.35187183e-27\n",
      " 4.25840721e-27]\n",
      "#########################################################\n",
      "65  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-6.32827124e-16 -2.88657986e-16 -3.88578059e-16 -1.11022302e-16\n",
      " -1.11022302e-16]\n",
      "#########################################################\n",
      "66  Iter:\n",
      "\n",
      "Gradient:\n",
      " [9.10484186e-27 5.74561858e-27 3.13577163e-27 6.08827504e-28\n",
      " 1.89925600e-27]\n",
      "#########################################################\n",
      "67  Iter:\n",
      "\n",
      "Gradient:\n",
      " [3.34948413e-27 2.11369495e-27 1.15358591e-27 2.23975122e-28\n",
      " 6.98697237e-28]\n",
      "#########################################################\n",
      "68  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.23220635e-27 7.77584918e-28 4.24380541e-28 8.23958427e-29\n",
      " 2.57036349e-28]\n",
      "#########################################################\n",
      "69  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.80966353e-15 -8.43769499e-16 -1.14352972e-15 -3.33066907e-16\n",
      " -3.33066907e-16]\n",
      "#########################################################\n",
      "70  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.62503148e-28 1.02550748e-28 5.59711632e-29 1.08673281e-29\n",
      " 3.38963754e-29]\n",
      "#########################################################\n",
      "71  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.80966353e-15 -8.43769499e-16 -1.14352972e-15 -3.33066907e-16\n",
      " -3.33066907e-16]\n",
      "#########################################################\n",
      "72  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.80966353e-15 -8.43769499e-16 -1.14352972e-15 -3.33066907e-16\n",
      " -3.33066907e-16]\n",
      "#########################################################\n",
      "73  Iter:\n",
      "\n",
      "Gradient:\n",
      " [3.52489168e-30 2.22721922e-30 1.21180617e-30 2.41755490e-31\n",
      " 7.32881049e-31]\n",
      "#########################################################\n",
      "74  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.17683641e-15 -5.55111512e-16 -7.54951657e-16 -2.22044605e-16\n",
      " -2.22044605e-16]\n",
      "#########################################################\n",
      "75  Iter:\n",
      "\n",
      "Gradient:\n",
      " [3.59164975e-18 2.66656384e-18 1.34369327e-18 2.72612753e-19\n",
      " 7.07332227e-19]\n",
      "#########################################################\n",
      "76  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.32129411e-18 9.80974020e-19 4.94317131e-19 1.00288628e-19\n",
      " 2.60212986e-19]\n",
      "#########################################################\n",
      "77  Iter:\n",
      "\n",
      "Gradient:\n",
      " [4.86076938e-19 3.60880173e-19 1.81849109e-19 3.68941242e-20\n",
      " 9.57270075e-20]\n",
      "#########################################################\n",
      "78  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.78817711e-19 1.32760396e-19 6.68985483e-20 1.35725897e-20\n",
      " 3.52159978e-20]\n",
      "#########################################################\n",
      "79  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.26558846e-15 -5.77267133e-16 -7.77131507e-16 -2.22039612e-16\n",
      " -2.22031650e-16]\n",
      "#########################################################\n",
      "80  Iter:\n",
      "\n",
      "Gradient:\n",
      " [2.42005107e-20 1.79672876e-20 9.05379621e-21 1.83686305e-21\n",
      " 4.76599949e-21]\n",
      "#########################################################\n",
      "81  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.26564535e-15 -5.77309363e-16 -7.77152787e-16 -2.22043929e-16\n",
      " -2.22042852e-16]\n",
      "#########################################################\n",
      "82  Iter:\n",
      "\n",
      "Gradient:\n",
      " [3.27528272e-21 2.43168196e-21 1.22533543e-21 2.48599992e-22\n",
      " 6.45027523e-22]\n",
      "#########################################################\n",
      "83  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.26565304e-15 -5.77315078e-16 -7.77155666e-16 -2.22044513e-16\n",
      " -2.22044368e-16]\n",
      "#########################################################\n",
      "84  Iter:\n",
      "\n",
      "Gradient:\n",
      " [4.43413212e-22 3.29205142e-22 1.65887950e-22 3.36558839e-23\n",
      " 8.73248948e-23]\n",
      "#########################################################\n",
      "85  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.26565408e-15 -5.77315852e-16 -7.77156056e-16 -2.22044593e-16\n",
      " -2.22044573e-16]\n",
      "#########################################################\n",
      "86  Iter:\n",
      "\n",
      "Gradient:\n",
      " [5.99608513e-23 4.45169931e-23 2.24323148e-23 4.55113704e-24\n",
      " 1.18085679e-23]\n",
      "#########################################################\n",
      "87  Iter:\n",
      "\n",
      "Gradient:\n",
      " [2.20583644e-23 1.63768865e-23 8.25238742e-24 1.67426975e-24\n",
      " 4.34412934e-24]\n",
      "#########################################################\n",
      "88  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.26565424e-15 -5.77315967e-16 -7.77156114e-16 -2.22044604e-16\n",
      " -2.22044603e-16]\n",
      "#########################################################\n",
      "89  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.26565425e-15 -5.77315971e-16 -7.77156116e-16 -2.22044605e-16\n",
      " -2.22044604e-16]\n",
      "#########################################################\n",
      "90  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.09028313e-24 8.09447790e-25 4.07896312e-25 8.27454808e-26\n",
      " 2.14721955e-25]\n",
      "#########################################################\n",
      "91  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.26565425e-15 -5.77315973e-16 -7.77156117e-16 -2.22044605e-16\n",
      " -2.22044605e-16]\n",
      "#########################################################\n",
      "92  Iter:\n",
      "\n",
      "Gradient:\n",
      " [1.02233755e-25 7.58428308e-26 3.82652300e-26 7.72260777e-27\n",
      " 2.01484475e-26]\n",
      "#########################################################\n",
      "93  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-6.32827124e-16 -2.88657986e-16 -3.88578059e-16 -1.11022302e-16\n",
      " -1.11022302e-16]\n",
      "#########################################################\n",
      "94  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-3.20965476e-14 -1.46771484e-14 -1.97730721e-14 -5.66213743e-15\n",
      " -5.66213743e-15]\n",
      "#########################################################\n",
      "95  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.18471118e-06 -5.40811372e-07 -7.28189066e-07 -2.08198859e-07\n",
      " -2.08198036e-07]\n",
      "#########################################################\n",
      "96  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-4.63880182e-07 -2.11755709e-07 -2.85122919e-07 -8.15197431e-08\n",
      " -8.15193847e-08]\n",
      "#########################################################\n",
      "97  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-5.61522525e-08 -2.56345823e-08 -3.45169634e-08 -9.86938142e-09\n",
      " -9.86934146e-09]\n",
      "#########################################################\n",
      "98  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-5.76757930e-09 -2.63285409e-09 -3.54507312e-09 -1.01358262e-09\n",
      " -1.01357922e-09]\n",
      "#########################################################\n",
      "99  Iter:\n",
      "\n",
      "Gradient:\n",
      " [-1.48803414e-10 -6.79528767e-11 -9.15074683e-11 -2.61719424e-11\n",
      " -2.61718425e-11]\n",
      "#########################################################\n"
     ]
    }
   ],
   "source": [
    "X_train = raw_data[:80]\n",
    "y_train = raw_label[:80]\n",
    "tinyml_logisticreg = LogisticRegression(max_iter=100,use_matrix=True)\n",
    "tinyml_logisticreg.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## Scikit-learn logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"Abalone_data/abalone.data\", delimiter=\",\", dtype=str)\n",
    "\n",
    "# Remove third class\n",
    "data = data[~(data[:, 0] == 'I')]\n",
    "np.random.shuffle(data)\n",
    "\n",
    "x = data[:,1:].astype(float)\n",
    "label = data[:, 0]\n",
    "unique, y = np.unique(label, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "partition = 0.8\n",
    "train_size = int(data.shape[0] * 0.8)\n",
    "\n",
    "train_data = x[:train_size]\n",
    "train_label = y[:train_size]\n",
    "\n",
    "test_data = x[train_size:]\n",
    "test_label = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5537918871252204\n"
     ]
    }
   ],
   "source": [
    "print(((pred == test_label).astype(int).sum())/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}